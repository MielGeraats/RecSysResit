{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b9fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lenskit.algorithms import Recommender\n",
    "from lenskit.algorithms.user_knn import UserUser\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d15bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ratings and movies csv files, drop the timestamp column (unused)\n",
    "ratings = pd.read_csv(\"preprocessed_dataset/ratings.csv\")\n",
    "ratings = ratings.drop('timestamp', axis=1)\n",
    "movies = pd.read_csv(\"preprocessed_dataset/movies.csv\", index_col=\"item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "836f4a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for generating random groups based on the ratings file\n",
    "def getGroups(ratings):\n",
    "    user_ids = ratings['user'].unique() # Sort by unique user IDs\n",
    "    random.shuffle(user_ids)\n",
    "    group_size = 4 # Group size can be determined here\n",
    "    random_groups = [user_ids[i:i + group_size] for i in range(0, len(user_ids), group_size)]\n",
    "\n",
    "    return random_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a239fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for training the UserUser recommender system using the train_data because of the Hold-Out validation strategy\n",
    "def trainModel(train_data):\n",
    "    user_user = UserUser(15, min_nbrs=3)\n",
    "    recsys = Recommender.adapt(user_user)\n",
    "    recsys.fit(train_data)\n",
    "    \n",
    "    return recsys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e3c4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for returning the ratings of a specific user\n",
    "def getUserRatings(ratings,user):\n",
    "    user_ratings = ratings[ratings['user'] == user]\n",
    "    user_ratings_series = user_ratings.set_index('item')['rating']\n",
    "    \n",
    "    return user_ratings_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c796222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for returning all items in the user_item_matrix for which the user does not have a rating yet (NaN)\n",
    "def getNaNList(user_item_matrix,user_id):\n",
    "    cols = user_item_matrix.loc[user_id]\n",
    "    nan_columns = cols[cols.isna()].index.tolist()\n",
    "    \n",
    "    return nan_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be816265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for returning the recommendations for a specific user using the passed trained recommender model\n",
    "def getRecommendation(recsys,user_item_matrix,user_id):\n",
    "    user_ratings = getUserRatings(ratings,user_id) # Get all existing ratings\n",
    "    items = getNaNList(user_item_matrix,user_id) # Get all unrated items\n",
    "    predicted_scores = recsys.predict_for_user(user_id, items, user_ratings)\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "        # Add predicted ratings to the matrix, clipped to a 0-5 interval\n",
    "        user_item_matrix.loc[user_id, items] = np.clip(predicted_scores,0,5)\n",
    "        \n",
    "    return user_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0247dffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for returning the top x recommendations for a given group using the additive aggregation strategy\n",
    "def getAdditiveOrder(user_item_matrix,group):\n",
    "    group_ratings = {}\n",
    "    group_uim = user_item_matrix.loc[group]\n",
    "    for item in group_uim: # For each item\n",
    "        total_rating = group_uim[item].sum() # Calculate the added scores of all group members\n",
    "        if item not in group_ratings: # Add item to array if not already present\n",
    "            group_ratings[item] = []\n",
    "        group_ratings[item].append(total_rating) # Add cumulative additive score to ratings array\n",
    "    result = pd.DataFrame(group_ratings) # Transform into DataFrame\n",
    "    ordered_items = result.max().sort_values(ascending=False) # Order items by size\n",
    "    \n",
    "    return ordered_items.head(5) # Return highest 5 predicted scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fed989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for returning the top x recommendations for a given group using the least misery aggregation strategy\n",
    "def getLeastMiseryOrder(user_item_matrix,group):\n",
    "    group_ratings = {}\n",
    "    group_uim = user_item_matrix.loc[group]\n",
    "    for item in group_uim: # For each item\n",
    "        min_rating = group_uim[item].min() # Calculate the lowest score from all group members\n",
    "        if item not in group_ratings: # Add item to array if not already present\n",
    "            group_ratings[item] = []\n",
    "        group_ratings[item].append(min_rating)  # Add lowest score to ratings array\n",
    "    result = pd.DataFrame(group_ratings) # Transform into DataFrame\n",
    "    ordered_items = result.max().sort_values(ascending=False) # Order items by size\n",
    "    \n",
    "    return ordered_items.head(5) # Return highest 5 predicted scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad73d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for returning the hits on the passed top 5 items (order) for a given group\n",
    "def getHits(group,order,ratings):\n",
    "    threshold = 3 # Minimum threshold for a hit can be determined here\n",
    "    hits = pd.Series(index=order.index, dtype=int) # Instantiate Series\n",
    "    for item in order.index: # For each passed item to be recommended\n",
    "        item_ratings = ratings.loc[ratings['item'] == item] # Find ratings for said item\n",
    "        relevance = sum( # Calculate relevance by calculating how many group members have rated the item above the threshold\n",
    "            item_ratings.loc[item_ratings['user'] == user, 'rating'].values[0] > threshold\n",
    "            for user in group if any(item_ratings['user'] == user)\n",
    "        )\n",
    "        hits[item] = relevance # Append the item's relevance\n",
    "\n",
    "    return hits # Return hits Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7df3a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for calculating the DCG\n",
    "def GetDCG(hits):\n",
    "    dcg = hits.iloc[0] # Start value is the relevance of the first item in the hits Series (rel_1)\n",
    "    for i, hit_value in enumerate(hits, 1): # For every other item in the hits Series\n",
    "        if i != 1: # Skip the first to avoid dividing by 0\n",
    "            value = (hit_value)/np.log2(i) # Calculate relevance / log2(rank)\n",
    "            dcg += value # Add to DCG\n",
    "\n",
    "    return dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f03baf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for calclating the IDCG\n",
    "def GetIDCG(hits):\n",
    "    hits = hits.sort_values(ascending=False) # Rank the hits Series based on relevance\n",
    "    ndcg = hits.iloc[0] # Start value is the relevance of the first item in the hits Series (rel_1)\n",
    "    for i, hit_value in enumerate(hits, 1): # For every other item in the hits Series\n",
    "        if i != 1: # Skip the first to avoid dividing by 0\n",
    "            value = (hit_value)/np.log2(i) # Calculate relevance / log2(rank)\n",
    "            ndcg += value # Add to DCG\n",
    "\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "352f93e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for calculating the nDCG\n",
    "def GetnDCG(group,order,ratings):\n",
    "    hits = getHits(group,order,ratings) # Get hits Series\n",
    "    dcg = GetDCG(hits) # Calculate DCG\n",
    "    if (dcg == 0): # If DCG is 0, IDCG is also 0 so return 0 as nDCG value\n",
    "        ndcg = 0\n",
    "    else: # Else, calculate IDCG and nDCG\n",
    "        idcg = GetIDCG(hits)\n",
    "        ndcg = dcg/idcg \n",
    "\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "812aa8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "could not load LIBBLAS: Could not find module 'libblas' (or one of its dependencies). Try using the full path with constructor syntax.\n"
     ]
    }
   ],
   "source": [
    "# Hold-out Validation using 20% test data, stratified on user so there are no missing users/items in any set\n",
    "train_data, test_data = train_test_split(ratings, test_size=0.2, stratify=ratings['user'])\n",
    "recsys = trainModel(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd820a26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
